{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NMT7.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/contentlab-io/ai_language_translation/blob/main/NMT7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1clSaPz3RWvz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e463bd8-16c1-47af-c13a-26100fc05b85"
      },
      "source": [
        "\r\n",
        "\r\n",
        "!pip install keras_self_attention\r\n",
        "\r\n",
        "\r\n",
        "#from translate.storage.tmx import tmxfile\r\n",
        "from keras.preprocessing.text import Tokenizer\r\n",
        "from keras.preprocessing.sequence import pad_sequences\r\n",
        "import re\r\n",
        "import array\r\n",
        "\r\n",
        "\r\n",
        "import warnings\r\n",
        "warnings.filterwarnings(\"ignore\")\r\n",
        "import numpy as np\r\n",
        "import string\r\n",
        "from numpy import array, argmax, random, take\r\n",
        "#for processing imported data\r\n",
        "import tensorflow as tf\r\n",
        "import pandas as pd\r\n",
        "#the RNN routines\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense, LSTM, Embedding, RepeatVector\r\n",
        "\r\n",
        "from keras.callbacks import ModelCheckpoint\r\n",
        "from keras.models import load_model\r\n",
        "from keras import optimizers\r\n",
        "\r\n",
        "#optional imports if you want to generate statistical graphs of the DMT\r\n",
        "#import matplotlib.pyplot as plt\r\n",
        "#from keras.utils import plot_model\r\n",
        "#import pydot\r\n",
        "\r\n",
        "\r\n",
        "from gensim.models import Word2Vec\r\n",
        "from gensim.test.utils import common_texts\r\n",
        "from keras_self_attention import SeqSelfAttention\r\n",
        "\r\n",
        "# function to read raw text file\r\n",
        "def read_text(filename):\r\n",
        "        # open the file\r\n",
        "        file = open(filename, mode='rt', encoding='utf-8')\r\n",
        "        \r\n",
        "        # read all text\r\n",
        "        text = file.read()\r\n",
        "        file.close()\r\n",
        "        return text\r\n",
        "\r\n",
        "\t\t\r\n",
        "# split a text into sentences\r\n",
        "def to_lines(text):\r\n",
        "      sents = text.strip().split('\\n')\r\n",
        "      sents = [i.split('\\t') for i in sents]\r\n",
        "      return sents\r\n",
        "\r\n",
        "### tokenizer ###\r\n",
        "def tokenization(lines):\r\n",
        "        #print(lines)\r\n",
        "        tokenizer = Tokenizer()\r\n",
        "\r\n",
        "        tokenizer.fit_on_texts(lines)\r\n",
        "        return tokenizer\r\n",
        "\r\n",
        "### encode ###\r\n",
        "def encode_sequences(tokenizer, length, lines):\r\n",
        "         # integer encode sequences\r\n",
        "         seq = tokenizer.texts_to_sequences(lines)\r\n",
        "         # pad sequences with 0 values\r\n",
        "         seq = pad_sequences(seq, maxlen=length, padding='post')\r\n",
        "         return seq\r\n",
        "### custom split train/test ###\r\n",
        "\r\n",
        "\r\n",
        "def split1(lines):\r\n",
        "        train=[]\r\n",
        "        test=[]\r\n",
        "        l=len(lines)\r\n",
        "        for i in range(0,l-1):\r\n",
        "                if (i%8!=0):\r\n",
        "                        test.append(lines[i])\r\n",
        "                else:\r\n",
        "                        train.append(lines[i])\r\n",
        "        return [train,test]\r\n",
        "\r\n",
        "def split_file(fname1,fname2):\r\n",
        "        content_array = []\r\n",
        "        with open(fname1) as f:\r\n",
        "                #Content_list is the list that contains the read lines.     \r\n",
        "                for line in f:\r\n",
        "                        tokens = line.split('\\t')\r\n",
        "                        content_array.append(tokens[0])\r\n",
        "                        \r\n",
        "                with open(fname2, \"w\") as txt_file:\r\n",
        "                    for line in content_array:\r\n",
        "                        txt_file.write(line+\"\\n\")\r\n",
        "\r\n",
        "\t\t\r\n",
        "\r\n",
        "def define_model(in_vocab,out_vocab, in_timesteps,out_timesteps,units,use_attention=1,use_word2vec=1,corpus=None):\r\n",
        "      model = Sequential()\r\n",
        "      if use_word2vec==0 :\r\n",
        "        model.add(Embedding(in_vocab, units, input_length=in_timesteps, mask_zero=True))\r\n",
        "      else :\r\n",
        "        model_w2v = Word2Vec(corpus_file=corpus, size=50, window=5, min_count=1, workers=4)\r\n",
        "        model_w2v.mask_zero = True\r\n",
        "        model.add(model_w2v.wv.get_keras_embedding(train_embeddings=True))\r\n",
        "        \r\n",
        "      model.add(LSTM(units))\r\n",
        "      model.add(RepeatVector(out_timesteps))\r\n",
        "\r\n",
        "      if use_attention == 1:\r\n",
        "        model.add(SeqSelfAttention(attention_activation='sigmoid'))\r\n",
        "\r\n",
        "      model.add(LSTM(units, return_sequences=True))\r\n",
        "      model.add(Dense(out_vocab, activation='softmax'))\r\n",
        "      return model\r\n",
        "\r\n",
        "def get_word(n, tokenizer):\r\n",
        "      for word, index in tokenizer.word_index.items():\r\n",
        "          if index == n:\r\n",
        "              return word\r\n",
        "      return None\r\n",
        "\r\n",
        "def train_model(path_to_data,path_to_model,use_attention=1,use_word2vec=1):\r\n",
        "\r\n",
        "  data = read_text(path_to_data)\r\n",
        "  en_ru = to_lines(data)\r\n",
        "  en_ru = array(en_ru)\r\n",
        "\r\n",
        "  #print(en_ru)\r\n",
        "\r\n",
        "  # prepare english tokenizer\r\n",
        "  en_tokenizer = tokenization(en_ru[:, 0])\r\n",
        "  en_vocab_size = len(en_tokenizer.word_index) + 1\r\n",
        "\r\n",
        "  en_length = 8\r\n",
        "  #print('English Vocabulary Size: %d' % en_vocab_size)\r\n",
        "\r\n",
        "  # prepare Russian tokenizer\r\n",
        "  ru_tokenizer = tokenization(en_ru[:, 1])\r\n",
        "  ru_vocab_size = len(ru_tokenizer.word_index) + 1\r\n",
        "\r\n",
        "  ru_length = 8\r\n",
        "  #print('Target Vocabulary Size: %d' % ru_vocab_size)\r\n",
        "\r\n",
        "  from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "  # split data into train and test set\r\n",
        "  train, test = train_test_split(en_ru, test_size=0.2, random_state = 12)\r\n",
        "\r\n",
        "  # prepare training data\r\n",
        "  #input == english\r\n",
        "  trainX = encode_sequences(en_tokenizer, en_length, train[:, 0])\r\n",
        "\r\n",
        "  #output == russian\r\n",
        "  trainY = encode_sequences(ru_tokenizer, ru_length, train[:, 1])\r\n",
        "\r\n",
        "  # prepare validation data\r\n",
        "  #input == english\r\n",
        "  testX = encode_sequences(en_tokenizer, en_length, test[:, 0])\r\n",
        "\r\n",
        "  #output == russian\r\n",
        "  testY = encode_sequences(ru_tokenizer, ru_length, test[:, 1])\r\n",
        "\r\n",
        "  corpus=None\r\n",
        "\r\n",
        "  if use_word2vec==1 :\r\n",
        "    corpus=\"tmp.txt\"\r\n",
        "    split_file(path_to_data,corpus)\r\n",
        "      \r\n",
        "  # model compilation\r\n",
        "  model = define_model(en_vocab_size, ru_vocab_size, en_length, ru_length, 512,use_attention,use_word2vec,corpus)\r\n",
        "  rms = optimizers.RMSprop(lr=0.001)\r\n",
        "  model.compile(optimizer=rms, loss='sparse_categorical_crossentropy')\r\n",
        "\r\n",
        "  #filename = 'model13'\r\n",
        "  filename = path_to_model\r\n",
        "\r\n",
        "  checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\r\n",
        "\r\n",
        "  with tf.device('/device:GPU:0'):\r\n",
        "    # train model\r\n",
        "    history = model.fit(trainX, trainY.reshape(trainY.shape[0], trainY.shape[1], 1),\r\n",
        "                      epochs=30, batch_size=512, validation_split = 0.2,callbacks=[checkpoint], \r\n",
        "                      verbose=1)\r\n",
        "            \r\n",
        "#end function\r\n",
        "\r\n",
        "def translate(path_to_data, path_to_file, path_to_model):\r\n",
        "\r\n",
        "  data = read_text(path_to_data)\r\n",
        "  en_ru = to_lines(data)\r\n",
        "  en_ru = array(en_ru)\r\n",
        "\r\n",
        "  #print(en_ru)\r\n",
        "\r\n",
        "  # prepare english tokenizer\r\n",
        "  en_tokenizer = tokenization(en_ru[:, 0])\r\n",
        "  en_vocab_size = len(en_tokenizer.word_index) + 1\r\n",
        "\r\n",
        "  en_length = 8\r\n",
        "  print('English Vocabulary Size: %d' % en_vocab_size)\r\n",
        "\r\n",
        "  # prepare Russian tokenizer\r\n",
        "  ru_tokenizer = tokenization(en_ru[:, 1])\r\n",
        "  ru_vocab_size = len(ru_tokenizer.word_index) + 1\r\n",
        "\r\n",
        "  print('ru_vocab_size Vocabulary Size: %d' % ru_vocab_size)\r\n",
        "\r\n",
        "  data2 = read_text(path_to_file)\r\n",
        "  en_ru2 = to_lines(data2)\r\n",
        "  en_ru2 = array(en_ru2)\r\n",
        "\r\n",
        "  testX1 = encode_sequences(en_tokenizer, en_length, en_ru2[:, 0])\r\n",
        "\r\n",
        "  model = load_model(path_to_model)\r\n",
        "\r\n",
        "  #predict (from english to dutch)\r\n",
        "  preds = model.predict_classes(testX1.reshape((testX1.shape[0],testX1.shape[1])))\r\n",
        "\r\n",
        "  #actuals_text=[]\r\n",
        "  preds_text = []\r\n",
        "  inputs_text=[]\r\n",
        "\r\n",
        "  idx=0\r\n",
        "\r\n",
        "  for i in preds:\r\n",
        "        idx=idx+1\r\n",
        "        temp = []\r\n",
        "        for j in range(len(i)):\r\n",
        "              t = get_word(i[j], ru_tokenizer)\r\n",
        "              if j > 0:\r\n",
        "                  if (t == get_word(i[j-1], ru_tokenizer)) or (t == None):\r\n",
        "                      temp.append('')\r\n",
        "                  else:\r\n",
        "                      temp.append(t)\r\n",
        "              else:\r\n",
        "                    if(t == None):\r\n",
        "                            temp.append('')\r\n",
        "                    else:\r\n",
        "                            temp.append(t)\r\n",
        "        preds_text.append(' '.join(temp))\r\n",
        "      \r\n",
        "  idx=0\r\n",
        "\t   \r\n",
        "  for i in testX1:\r\n",
        "        idx=idx+1\r\n",
        "\r\n",
        "        temp = []\r\n",
        "        for j in range(len(i)):\r\n",
        "              t = get_word(i[j], en_tokenizer)\r\n",
        "              if j > 0:\r\n",
        "                  if (t == get_word(i[j-1], en_tokenizer)) or (t == None):\r\n",
        "                      temp.append('')\r\n",
        "                  else:\r\n",
        "                      temp.append(t)\r\n",
        "              else:\r\n",
        "                    if(t == None):\r\n",
        "                            temp.append('')\r\n",
        "                    else:\r\n",
        "                            temp.append(t)\r\n",
        "        inputs_text.append(' '.join(temp))\r\n",
        "\r\n",
        "  pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\r\n",
        "\r\n",
        "\r\n",
        "  pred_df = pd.DataFrame({'input' : inputs_text , 'model translation' : preds_text})\r\n",
        "\r\n",
        "  print(pred_df)\r\n",
        "\r\n",
        "#end function\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "train_model(\"fra.txt\",\"model_fra2\",1,1)\r\n",
        "translate(\"fra.txt\",\"test.txt\",\"model_fra2\")\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras_self_attention in /usr/local/lib/python3.6/dist-packages (0.49.0)\n",
            "Requirement already satisfied: Keras in /usr/local/lib/python3.6/dist-packages (from keras_self_attention) (2.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from keras_self_attention) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras->keras_self_attention) (1.4.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras->keras_self_attention) (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras->keras_self_attention) (2.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->Keras->keras_self_attention) (1.15.0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:gensim.models.base_any2vec:consider setting layer size to a multiple of 4 for greater performance\n",
            "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "232/232 [==============================] - 54s 223ms/step - loss: 5.7407 - val_loss: 4.8199\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 4.81992, saving model to model_fra2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_4_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_4_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_fra2/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_fra2/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/30\n",
            "232/232 [==============================] - 51s 218ms/step - loss: 4.5913 - val_loss: 4.1393\n",
            "\n",
            "Epoch 00002: val_loss improved from 4.81992 to 4.13935, saving model to model_fra2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_4_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_4_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_fra2/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_fra2/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 3/30\n",
            "232/232 [==============================] - 50s 216ms/step - loss: 3.9527 - val_loss: 3.7266\n",
            "\n",
            "Epoch 00003: val_loss improved from 4.13935 to 3.72659, saving model to model_fra2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_4_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_4_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_fra2/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_fra2/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 4/30\n",
            "232/232 [==============================] - 51s 219ms/step - loss: 3.5087 - val_loss: 3.4495\n",
            "\n",
            "Epoch 00004: val_loss improved from 3.72659 to 3.44950, saving model to model_fra2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_4_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_4_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_fra2/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_fra2/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 5/30\n",
            "232/232 [==============================] - 51s 218ms/step - loss: 3.1843 - val_loss: 3.2515\n",
            "\n",
            "Epoch 00005: val_loss improved from 3.44950 to 3.25147, saving model to model_fra2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_4_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_4_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_fra2/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_fra2/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 6/30\n",
            "232/232 [==============================] - 51s 218ms/step - loss: 2.9406 - val_loss: 3.1234\n",
            "\n",
            "Epoch 00006: val_loss improved from 3.25147 to 3.12338, saving model to model_fra2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_4_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_4_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_fra2/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_fra2/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 7/30\n",
            "232/232 [==============================] - 51s 219ms/step - loss: 2.7348 - val_loss: 3.0069\n",
            "\n",
            "Epoch 00007: val_loss improved from 3.12338 to 3.00689, saving model to model_fra2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_4_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_4_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_fra2/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_fra2/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 8/30\n",
            "232/232 [==============================] - 51s 218ms/step - loss: 2.5477 - val_loss: 2.9319\n",
            "\n",
            "Epoch 00008: val_loss improved from 3.00689 to 2.93195, saving model to model_fra2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_4_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_4_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_fra2/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_fra2/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 9/30\n",
            "232/232 [==============================] - 51s 219ms/step - loss: 2.4027 - val_loss: 2.8742\n",
            "\n",
            "Epoch 00009: val_loss improved from 2.93195 to 2.87424, saving model to model_fra2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_4_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_4_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_fra2/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_fra2/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 10/30\n",
            "232/232 [==============================] - 51s 218ms/step - loss: 2.2622 - val_loss: 2.8380\n",
            "\n",
            "Epoch 00010: val_loss improved from 2.87424 to 2.83799, saving model to model_fra2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_4_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_4_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_fra2/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_fra2/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 11/30\n",
            "232/232 [==============================] - 51s 219ms/step - loss: 2.1454 - val_loss: 2.8107\n",
            "\n",
            "Epoch 00011: val_loss improved from 2.83799 to 2.81069, saving model to model_fra2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_4_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_4_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_fra2/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_fra2/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 12/30\n",
            "232/232 [==============================] - 51s 219ms/step - loss: 2.0208 - val_loss: 2.7791\n",
            "\n",
            "Epoch 00012: val_loss improved from 2.81069 to 2.77911, saving model to model_fra2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_4_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_4_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_fra2/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_fra2/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 13/30\n",
            "232/232 [==============================] - 51s 219ms/step - loss: 1.9211 - val_loss: 2.7639\n",
            "\n",
            "Epoch 00013: val_loss improved from 2.77911 to 2.76394, saving model to model_fra2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_4_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_4_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_fra2/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_fra2/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 14/30\n",
            "232/232 [==============================] - 51s 219ms/step - loss: 1.8232 - val_loss: 2.7686\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 2.76394\n",
            "Epoch 15/30\n",
            "232/232 [==============================] - 50s 216ms/step - loss: 1.7339 - val_loss: 2.7570\n",
            "\n",
            "Epoch 00015: val_loss improved from 2.76394 to 2.75702, saving model to model_fra2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_4_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_4_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_fra2/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_fra2/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 16/30\n",
            "232/232 [==============================] - 51s 221ms/step - loss: 1.6485 - val_loss: 2.7592\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 2.75702\n",
            "Epoch 17/30\n",
            "232/232 [==============================] - 50s 216ms/step - loss: 1.5694 - val_loss: 2.7679\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 2.75702\n",
            "Epoch 18/30\n",
            "232/232 [==============================] - 51s 219ms/step - loss: 1.5004 - val_loss: 2.7873\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 2.75702\n",
            "Epoch 19/30\n",
            "232/232 [==============================] - 50s 218ms/step - loss: 1.4325 - val_loss: 2.7890\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 2.75702\n",
            "Epoch 20/30\n",
            "232/232 [==============================] - 51s 219ms/step - loss: 1.3657 - val_loss: 2.8115\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 2.75702\n",
            "Epoch 21/30\n",
            "232/232 [==============================] - 51s 218ms/step - loss: 1.3056 - val_loss: 2.8260\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 2.75702\n",
            "Epoch 22/30\n",
            "232/232 [==============================] - 51s 219ms/step - loss: 1.2498 - val_loss: 2.8359\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 2.75702\n",
            "Epoch 23/30\n",
            "232/232 [==============================] - 51s 218ms/step - loss: 1.2015 - val_loss: 2.8610\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 2.75702\n",
            "Epoch 24/30\n",
            "232/232 [==============================] - 50s 218ms/step - loss: 1.1538 - val_loss: 2.8796\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 2.75702\n",
            "Epoch 25/30\n",
            "232/232 [==============================] - 50s 218ms/step - loss: 1.1061 - val_loss: 2.9046\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 2.75702\n",
            "Epoch 26/30\n",
            "232/232 [==============================] - 51s 219ms/step - loss: 1.0709 - val_loss: 2.9197\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 2.75702\n",
            "Epoch 27/30\n",
            "232/232 [==============================] - 50s 218ms/step - loss: 1.0300 - val_loss: 2.9516\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 2.75702\n",
            "Epoch 28/30\n",
            "232/232 [==============================] - 50s 218ms/step - loss: 0.9915 - val_loss: 2.9600\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 2.75702\n",
            "Epoch 29/30\n",
            "232/232 [==============================] - 50s 218ms/step - loss: 0.9543 - val_loss: 2.9818\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 2.75702\n",
            "Epoch 30/30\n",
            "232/232 [==============================] - 51s 219ms/step - loss: 0.9266 - val_loss: 3.0000\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 2.75702\n",
            "English Vocabulary Size: 15046\n",
            "ru_vocab_size Vocabulary Size: 31585\n",
            "                        input    model translation\n",
            "0  please translate this       veuillez ceci      \n",
            "1          i like to read        j'aime lire      \n",
            "2             my name is           c'est nom      \n",
            "3         are delicious             les  sont     \n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}